{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfced003",
   "metadata": {},
   "source": [
    "# Scrape Enrichment Data using OpenStreetMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Fetching POIs for: Mitte\n",
      "ðŸ”Ž Fetching POIs for: Moabit\n",
      "ðŸ”Ž Fetching POIs for: Hansaviertel\n",
      "ðŸ”Ž Fetching POIs for: Tiergarten\n",
      "ðŸ”Ž Fetching POIs for: Wedding\n",
      "ðŸ”Ž Fetching POIs for: Gesundbrunnen\n",
      "ðŸ”Ž Fetching POIs for: Friedrichshain\n",
      "ðŸ”Ž Fetching POIs for: Kreuzberg\n",
      "ðŸ”Ž Fetching POIs for: Prenzlauer Berg\n",
      "ðŸ”Ž Fetching POIs for: WeiÃŸensee\n",
      "ðŸ”Ž Fetching POIs for: Blankenburg\n",
      "ðŸ”Ž Fetching POIs for: Heinersdorf\n",
      "ðŸ”Ž Fetching POIs for: Karow\n",
      "ðŸ”Ž Fetching POIs for: Stadtrandsiedlung Malchow\n",
      "ðŸ”Ž Fetching POIs for: Pankow\n",
      "ðŸ”Ž Fetching POIs for: Blankenfelde\n",
      "ðŸ”Ž Fetching POIs for: Buch\n",
      "ðŸ”Ž Fetching POIs for: FranzÃ¶sisch Buchholz\n",
      "ðŸ”Ž Fetching POIs for: NiederschÃ¶nhausen\n",
      "ðŸ”Ž Fetching POIs for: Rosenthal\n",
      "ðŸ”Ž Fetching POIs for: Wilhelmsruh\n",
      "ðŸ”Ž Fetching POIs for: Charlottenburg\n",
      "ðŸ”Ž Fetching POIs for: Wilmersdorf\n",
      "ðŸ”Ž Fetching POIs for: Schmargendorf\n",
      "ðŸ”Ž Fetching POIs for: Grunewald\n",
      "ðŸ”Ž Fetching POIs for: Westend\n",
      "ðŸ”Ž Fetching POIs for: Charlottenburg-Nord\n",
      "ðŸ”Ž Fetching POIs for: Halensee\n",
      "ðŸ”Ž Fetching POIs for: Spandau\n",
      "ðŸ”Ž Fetching POIs for: Haselhorst\n",
      "ðŸ”Ž Fetching POIs for: Siemensstadt\n",
      "ðŸ”Ž Fetching POIs for: Staaken\n",
      "ðŸ”Ž Fetching POIs for: Gatow\n",
      "ðŸ”Ž Fetching POIs for: Kladow\n",
      "ðŸ”Ž Fetching POIs for: Hakenfelde\n",
      "ðŸ”Ž Fetching POIs for: Falkenhagener Feld\n",
      "ðŸ”Ž Fetching POIs for: Wilhelmstadt\n",
      "ðŸ”Ž Fetching POIs for: Steglitz\n",
      "ðŸ”Ž Fetching POIs for: Lichterfelde\n",
      "ðŸ”Ž Fetching POIs for: Lankwitz\n",
      "ðŸ”Ž Fetching POIs for: Zehlendorf\n",
      "ðŸ”Ž Fetching POIs for: Dahlem\n",
      "ðŸ”Ž Fetching POIs for: Nikolassee\n",
      "ðŸ”Ž Fetching POIs for: Wannsee\n",
      "ðŸ”Ž Fetching POIs for: SchÃ¶neberg\n",
      "ðŸ”Ž Fetching POIs for: Friedenau\n",
      "ðŸ”Ž Fetching POIs for: Tempelhof\n",
      "ðŸ”Ž Fetching POIs for: Mariendorf\n",
      "ðŸ”Ž Fetching POIs for: Marienfelde\n",
      "ðŸ”Ž Fetching POIs for: Lichtenrade\n",
      "ðŸ”Ž Fetching POIs for: NeukÃ¶lln\n",
      "ðŸ”Ž Fetching POIs for: Britz\n",
      "ðŸ”Ž Fetching POIs for: Buckow\n",
      "ðŸ”Ž Fetching POIs for: Rudow\n",
      "ðŸ”Ž Fetching POIs for: Gropiusstadt\n",
      "ðŸ”Ž Fetching POIs for: Alt-Treptow\n",
      "ðŸ”Ž Fetching POIs for: PlÃ¤nterwald\n",
      "ðŸ”Ž Fetching POIs for: Baumschulenweg\n",
      "ðŸ”Ž Fetching POIs for: Johannisthal\n",
      "ðŸ”Ž Fetching POIs for: NiederschÃ¶neweide\n",
      "ðŸ”Ž Fetching POIs for: Altglienicke\n",
      "ðŸ”Ž Fetching POIs for: Adlershof\n",
      "ðŸ”Ž Fetching POIs for: Bohnsdorf\n",
      "ðŸ”Ž Fetching POIs for: OberschÃ¶neweide\n",
      "ðŸ”Ž Fetching POIs for: KÃ¶penick\n",
      "ðŸ”Ž Fetching POIs for: Friedrichshagen\n",
      "ðŸ”Ž Fetching POIs for: Rahnsdorf\n",
      "ðŸ”Ž Fetching POIs for: GrÃ¼nau\n",
      "ðŸ”Ž Fetching POIs for: MÃ¼ggelheim\n",
      "ðŸ”Ž Fetching POIs for: SchmÃ¶ckwitz\n",
      "ðŸ”Ž Fetching POIs for: Marzahn\n",
      "ðŸ”Ž Fetching POIs for: Biesdorf\n",
      "ðŸ”Ž Fetching POIs for: Kaulsdorf\n",
      "ðŸ”Ž Fetching POIs for: Mahlsdorf\n",
      "ðŸ”Ž Fetching POIs for: Hellersdorf\n",
      "ðŸ”Ž Fetching POIs for: Friedrichsfelde\n",
      "ðŸ”Ž Fetching POIs for: Karlshorst\n",
      "ðŸ”Ž Fetching POIs for: Lichtenberg\n",
      "ðŸ”Ž Fetching POIs for: Falkenberg\n",
      "ðŸ”Ž Fetching POIs for: Malchow\n",
      "ðŸ”Ž Fetching POIs for: Wartenberg\n",
      "ðŸ”Ž Fetching POIs for: Neu-HohenschÃ¶nhausen\n",
      "ðŸ”Ž Fetching POIs for: Alt-HohenschÃ¶nhausen\n",
      "ðŸ”Ž Fetching POIs for: Fennpfuhl\n",
      "ðŸ”Ž Fetching POIs for: Rummelsburg\n",
      "ðŸ”Ž Fetching POIs for: Reinickendorf\n",
      "ðŸ”Ž Fetching POIs for: Tegel\n",
      "ðŸ”Ž Fetching POIs for: KonradshÃ¶he\n",
      "ðŸ”Ž Fetching POIs for: Heiligensee\n",
      "ðŸ”Ž Fetching POIs for: Frohnau\n",
      "ðŸ”Ž Fetching POIs for: Hermsdorf\n",
      "ðŸ”Ž Fetching POIs for: Waidmannslust\n",
      "ðŸ”Ž Fetching POIs for: LÃ¼bars\n",
      "ðŸ”Ž Fetching POIs for: Wittenau\n",
      "ðŸ”Ž Fetching POIs for: MÃ¤rkisches Viertel\n",
      "ðŸ”Ž Fetching POIs for: Borsigwalde\n",
      "\n",
      "âœ… Saved 43563 POIs to 'berlin_pois.geojson'\n",
      "âš ï¸  0 Ortsteile failed and were saved to 'failed_ortsteile.txt'\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osmnx.features import features_from_polygon\n",
    "from shapely.geometry import Polygon\n",
    "import time\n",
    "\n",
    "# Load Ortsteil polygons\n",
    "gdf_boundary = gpd.read_file(\"../data/spatial_data/lor_ortsteile.geojson\")\n",
    "\n",
    "# Define tags for POIs\n",
    "tags = {\n",
    "    \"shop\": [\"supermarket\"],\n",
    "    \"amenity\": [\n",
    "        \"cafe\", \"restaurant\", \"bar\", \"nightclub\",\n",
    "        \"school\", \"kindergarten\", \"university\",\n",
    "        \"clinic\", \"hospital\", \"pharmacy\"\n",
    "    ],\n",
    "    \"leisure\": [\"park\", \"playground\"],\n",
    "    \"landuse\": [\"grass\", \"forest\"],\n",
    "    \"natural\": [\"wood\"]\n",
    "}\n",
    "\n",
    "# Empty lists to collect data\n",
    "pois_list = []\n",
    "failed_ortsteile = []\n",
    "\n",
    "# Loop through Ortsteile\n",
    "for i, row in gdf_boundary.iterrows():\n",
    "    ortsteil_name = row[\"OTEIL\"]  # or possibly row[\"spatial_name\"] if you use that one\n",
    "    polygon = row['geometry']\n",
    "    \n",
    "    try:\n",
    "        print(f\"ðŸ”Ž Fetching POIs for: {ortsteil_name}\")\n",
    "        pois = features_from_polygon(polygon, tags)\n",
    "        pois[\"ortsteil\"] = ortsteil_name\n",
    "        pois_list.append(pois)\n",
    "        time.sleep(2)  # polite pause between requests\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed for {ortsteil_name}: {e}\")\n",
    "        failed_ortsteile.append(ortsteil_name)\n",
    "\n",
    "# Save failed list (optional)\n",
    "with open(\"failed_ortsteile.txt\", \"w\") as f:\n",
    "    for item in failed_ortsteile:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "# Combine successful POIs\n",
    "gdf_pois = gpd.GeoDataFrame(pd.concat(pois_list, ignore_index=True))\n",
    "\n",
    "# Save to file\n",
    "gdf_pois.to_file(\"berlin_pois.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"\\nâœ… Saved {len(gdf_pois)} POIs to 'berlin_pois.geojson'\")\n",
    "print(f\"âš ï¸  {len(failed_ortsteile)} Ortsteile failed and were saved to 'failed_ortsteile.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42254c41",
   "metadata": {},
   "source": [
    "# Create CSV file Subdistricts with pois features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field contact:phone:description: unsupported OGR type: 10\n",
      "Skipping field opening_hours:checkin: unsupported OGR type: 10\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osmnx.features import features_from_polygon\n",
    "from shapely.geometry import Polygon\n",
    "import time\n",
    "\n",
    "# Load existing Berlin POIs\n",
    "gdf_pois = gpd.read_file(\"berlin_pois.geojson\")\n",
    "\n",
    "# Define tags for POIs\n",
    "tags = {\n",
    "    \"shop\": [\"supermarket\"],\n",
    "    \"amenity\": [\n",
    "        \"cafe\", \"restaurant\", \"bar\", \"nightclub\",\n",
    "        \"school\", \"kindergarten\", \"university\",\n",
    "        \"clinic\", \"hospital\", \"pharmacy\"\n",
    "    ],\n",
    "    \"leisure\": [\"park\", \"playground\"],\n",
    "    \"landuse\": [\"grass\", \"forest\"],\n",
    "    \"natural\": [\"wood\"]\n",
    "}\n",
    "\n",
    "# Flatten tag values into a new column\n",
    "gdf_pois[\"main_tag\"] = gdf_pois.apply(\n",
    "    lambda row: next((k for k in tags.keys() if k in row and pd.notnull(row[k])), None), axis=1\n",
    ")\n",
    "\n",
    "gdf_pois[\"tag_value\"] = gdf_pois.apply(\n",
    "    lambda row: row[row[\"main_tag\"]] if pd.notnull(row[\"main_tag\"]) else None, axis=1\n",
    ")\n",
    "\n",
    "# Group by Ortsteil and tag value\n",
    "poi_counts = gdf_pois.groupby([\"ortsteil\", \"tag_value\"]).size().unstack(fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cd7bf",
   "metadata": {},
   "source": [
    "# Clean up extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760ca04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playground          96\n",
      "school              96\n",
      "grass               96\n",
      "park                96\n",
      "restaurant          95\n",
      "kindergarten        95\n",
      "supermarket         91\n",
      "cafe                91\n",
      "wood                88\n",
      "pharmacy            88\n",
      "forest              80\n",
      "bar                 61\n",
      "clinic              57\n",
      "hospital            35\n",
      "university          30\n",
      "nightclub           29\n",
      "bakery              23\n",
      "garden              19\n",
      "deli                 9\n",
      "coffee               9\n",
      "convenience          5\n",
      "confectionery        5\n",
      "alcohol              4\n",
      "community_centre     4\n",
      "pastry               4\n",
      "dog_park             3\n",
      "kiosk                3\n",
      "tea                  3\n",
      "ice_cream            3\n",
      "pitch                2\n",
      "hairdresser          2\n",
      "books                2\n",
      "bathing_place        2\n",
      "animal_training      1\n",
      "antiques             1\n",
      "wine                 1\n",
      "vacant               1\n",
      "art                  1\n",
      "travel_agency        1\n",
      "theatre              1\n",
      "tea;art              1\n",
      "bakery;pastry        1\n",
      "stationery           1\n",
      "second_hand          1\n",
      "butcher              1\n",
      "greengrocer          1\n",
      "childcare            1\n",
      "clothes              1\n",
      "electronics          1\n",
      "fitness_station      1\n",
      "parking              1\n",
      "florist              1\n",
      "fountain             1\n",
      "nature_reserve       1\n",
      "meadow               1\n",
      "marina               1\n",
      "greenfield           1\n",
      "yes                  1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"berlin_poi_counts_per_ortsteil.csv\")\n",
    "\n",
    "# Count how many subdistricts have > 0 for each POI type\n",
    "poi_presence = (df.drop(columns=\"ortsteil\") > 0).sum().sort_values(ascending=False)\n",
    "print(poi_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f41f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_columns = {\n",
    "    \"cafes\": [\"cafe\", \"coffee\", \"tea\"],\n",
    "    \"bakeries\": [\"bakery\", \"pastry\", \"bakery;pastry\"],\n",
    "    \"green_space\": [\"park\", \"forest\", \"meadow\", \"wood\", \"grass\"],\n",
    "    \"schools\": [\"school\", \"kindergarten\", \"university\"],\n",
    "    \"medical\": [\"clinic\", \"hospital\", \"pharmacy\"]\n",
    "}\n",
    "\n",
    "# Aggregate groups\n",
    "for new_col, tags in grouped_columns.items():\n",
    "    df[new_col] = df[tags].sum(axis=1)\n",
    "    df.drop(columns=tags, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b184ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "df.to_csv(\"berlin_poi_counts_per_ortsteil.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3c2b4",
   "metadata": {},
   "source": [
    "# Merge with subdistrict master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c04eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merge successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def normalize_ortsteil(name):\n",
    "    if pd.isnull(name):\n",
    "        return \"\"\n",
    "    # Replace umlauts\n",
    "    name = name.replace(\"Ã¤\", \"ae\").replace(\"Ã¶\", \"oe\").replace(\"Ã¼\", \"ue\").replace(\"ÃŸ\", \"ss\")\n",
    "    # Lowercase and strip\n",
    "    return name.lower().strip()\n",
    "\n",
    "# Load datasets\n",
    "df_master = pd.read_csv(\"../data/cleaned_data/berlin_ortsteil_table.csv\")\n",
    "df_poi = pd.read_csv(\"berlin_poi_counts_per_ortsteil.csv\")\n",
    "\n",
    "# Normalize ortsteil names in both datasets\n",
    "df_master[\"ortsteil_norm\"] = df_master[\"ortsteil\"].apply(normalize_ortsteil)\n",
    "df_poi[\"ortsteil_norm\"] = df_poi[\"ortsteil\"].apply(normalize_ortsteil)\n",
    "\n",
    "# Merge on normalized names\n",
    "df_merged = df_master.merge(df_poi, how=\"left\", on=\"ortsteil_norm\", suffixes=(\"\", \"_poi\"))\n",
    "\n",
    "# Drop helper column if needed\n",
    "df_merged.drop(columns=[\"ortsteil_norm\", \"ortsteil_poi\"], inplace=True)\n",
    "\n",
    "# Fill POI NaNs with 0\n",
    "poi_columns = df_poi.columns.difference(['ortsteil', 'ortsteil_norm'])\n",
    "df_merged[poi_columns] = df_merged[poi_columns].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Save result\n",
    "df_merged.to_csv(\"berlin_ortsteil_master_with_poi_features.csv\", index=False)\n",
    "print(\"âœ… Merge successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e3e21",
   "metadata": {},
   "source": [
    "# Merge District and Subdistrict level master tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17b3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sub = pd.read_csv('../data/master_tables/berlin_ortsteil_master_with_poi_features.csv')\n",
    "df_dist = pd.read_csv('../data/master_tables/berlin_bezirk_master_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e767ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_sub.merge(df_dist, on=\"bezirk\", how=\"left\")\n",
    "df_full.to_csv(\"berlin_final_master_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5dc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
